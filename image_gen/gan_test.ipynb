{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gan import GANTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_gan = GANTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_gan.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_samp = new_gan.model.validation_z.type_as(new_gan.model.generator.lin1.weight)\n",
    "# sample_imgs = new_gan.model(validation_samp).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# for i in range(sample_imgs.size(0)):\n",
    "#     plt.subplot(2, 3, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     plt.imshow(sample_imgs.detach()[i, 0, :, :], cmap='gray_r', interpolation='none')\n",
    "#     plt.title(\"Generated Images\")\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader Test\n",
    "\n",
    "Let's test the data loader we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_new import AnimeDataLoader, AnimeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/mgfos207/Desktop/PetProjects/DLDataPreproccessing/test_faces_split/train\"\n",
    "anime_data_loader = AnimeDataLoader((120,120), 128, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb = torch.randn(128, 128, 1, 1) #\n",
    "image_size = 128\n",
    "batch_size = 20\n",
    "latent_size = 128\n",
    "xb = torch.randn(batch_size, latent_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "devxb = xb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = AnimeGAN(anime_data_loader.data_loader, devxb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gan.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_imgs = gen(xb)\n",
    "fake_imgs = gen(devxb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01090860366821289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5870eaa5610c48b894386aca803ddb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([72, 1])) that is different to the input size (torch.Size([72, 16])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mgfos207/Desktop/PetProjects/MicahGan/image_gen/gan_test.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mgfos207/Desktop/PetProjects/MicahGan/image_gen/gan_test.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gan\u001b[39m.\u001b[39;49mfit(\u001b[39m100\u001b[39;49m, \u001b[39m.00003\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/PetProjects/MicahGan/image_gen/dataloader_new.py:197\u001b[0m, in \u001b[0;36mAnimeGAN.fit\u001b[0;34m(self, epochs, lr, start_idx)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    195\u001b[0m     \u001b[39mfor\u001b[39;00m real_images, _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl):\n\u001b[1;32m    196\u001b[0m         \u001b[39m# Train discriminator\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m         loss_d, real_score, fake_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_discriminator(real_images, opt_d)\n\u001b[1;32m    198\u001b[0m         \u001b[39m# Train generator\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         loss_g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_generator(opt_g)\n",
      "File \u001b[0;32m~/Desktop/PetProjects/MicahGan/image_gen/dataloader_new.py:133\u001b[0m, in \u001b[0;36mAnimeGAN.train_discriminator\u001b[0;34m(self, real_images, opt_d)\u001b[0m\n\u001b[1;32m    131\u001b[0m real_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator(real_images)\n\u001b[1;32m    132\u001b[0m real_targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(real_images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 133\u001b[0m real_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(real_preds, real_targets)\n\u001b[1;32m    134\u001b[0m real_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(real_preds)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    136\u001b[0m \u001b[39m# Generate fake images\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/micahTestGAN/lib/python3.10/site-packages/torch/nn/functional.py:3113\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3111\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3112\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3116\u001b[0m     )\n\u001b[1;32m   3118\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([72, 1])) that is different to the input size (torch.Size([72, 16])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "gan.fit(100, .00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daev_xb = xb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = gen(xb).to(device)\n",
    "# fake_img = gen(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fake_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_imgs = denorm(fake_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.show_images(fake_imgs.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.show_images(fk_imgs.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('micahTestGAN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2a133db65b2e59384fd16ea356480d12da492e70e0c8c7f960c4d98941d189a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
